{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importation des librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pnd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lecture du fichier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "observations = pnd.read_csv(\"datas/sonar.all-data.csv\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0371</td>\n",
       "      <td>0.0428</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.0954</td>\n",
       "      <td>0.0986</td>\n",
       "      <td>0.1539</td>\n",
       "      <td>0.1601</td>\n",
       "      <td>0.3109</td>\n",
       "      <td>0.2111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.0843</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.1183</td>\n",
       "      <td>0.2583</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.3481</td>\n",
       "      <td>0.3337</td>\n",
       "      <td>0.2872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.1099</td>\n",
       "      <td>0.1083</td>\n",
       "      <td>0.0974</td>\n",
       "      <td>0.2280</td>\n",
       "      <td>0.2431</td>\n",
       "      <td>0.3771</td>\n",
       "      <td>0.5598</td>\n",
       "      <td>0.6194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0623</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.1098</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.1264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.0762</td>\n",
       "      <td>0.0666</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.0590</td>\n",
       "      <td>0.0649</td>\n",
       "      <td>0.1209</td>\n",
       "      <td>0.2467</td>\n",
       "      <td>0.3564</td>\n",
       "      <td>0.4459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0       1       2       3       4       5       6       7       8   \\\n",
       "0  0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109   \n",
       "1  0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n",
       "2  0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n",
       "3  0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n",
       "4  0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n",
       "\n",
       "       9   ...      51      52      53      54      55      56      57  \\\n",
       "0  0.2111  ...  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180  0.0084   \n",
       "1  0.2872  ...  0.0084  0.0089  0.0048  0.0094  0.0191  0.0140  0.0049   \n",
       "2  0.6194  ...  0.0232  0.0166  0.0095  0.0180  0.0244  0.0316  0.0164   \n",
       "3  0.1264  ...  0.0121  0.0036  0.0150  0.0085  0.0073  0.0050  0.0044   \n",
       "4  0.4459  ...  0.0031  0.0054  0.0105  0.0110  0.0015  0.0072  0.0048   \n",
       "\n",
       "       58      59  60  \n",
       "0  0.0090  0.0032   R  \n",
       "1  0.0052  0.0044   R  \n",
       "2  0.0095  0.0078   R  \n",
       "3  0.0040  0.0117   R  \n",
       "4  0.0107  0.0094   R  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observations.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nombre de colonnes du fichier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nbr colonnes:  61\n"
     ]
    }
   ],
   "source": [
    "print(\"Nbr colonnes: \",len(observations.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Données du sonar - pour l'apprentissage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.02  , 0.0371, 0.0428, ..., 0.0084, 0.009 , 0.0032],\n",
       "       [0.0453, 0.0523, 0.0843, ..., 0.0049, 0.0052, 0.0044],\n",
       "       [0.0262, 0.0582, 0.1099, ..., 0.0164, 0.0095, 0.0078],\n",
       "       ...,\n",
       "       [0.0522, 0.0437, 0.018 , ..., 0.0138, 0.0077, 0.0031],\n",
       "       [0.0303, 0.0353, 0.049 , ..., 0.0079, 0.0036, 0.0048],\n",
       "       [0.026 , 0.0363, 0.0136, ..., 0.0036, 0.0061, 0.0115]])"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = observations[observations.columns[0:60]].values\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Récupération des libellés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      R\n",
       "1      R\n",
       "2      R\n",
       "3      R\n",
       "4      R\n",
       "      ..\n",
       "203    M\n",
       "204    M\n",
       "205    M\n",
       "206    M\n",
       "207    M\n",
       "Name: 60, Length: 208, dtype: object"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = observations[observations.columns[60]]\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import du LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On encode : Les mines sont égales à 0 et les rochers égaux à 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "encoder.fit(y)\n",
    "y = encoder.transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On ajoute un encodage pour créer des classes, si c'est une mine [1,0], si c'est un rocher [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_labels = len(y)\n",
    "n_unique_labels = len(np.unique(y))\n",
    "one_hot_encode = np.zeros((n_labels,n_unique_labels))\n",
    "one_hot_encode[np.arange(n_labels),y] = 1\n",
    "Y=one_hot_encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.]])"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verification en prenant les enregistrement 0 et 97"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classe Rocher: 1\n"
     ]
    }
   ],
   "source": [
    "print(\"Classe Rocher:\",int(Y[0][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classe Mine: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Classe Mine:\",int(Y[97][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CREATION DES JEUX D'APPRENTISSAGE ET DE TEST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On mélange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "X, Y = shuffle(X, Y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation des jeux d'apprentissage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_x, test_x, train_y, test_y = train_test_split(X, Y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAMETRAGE DU RESEAU DE  NEURONES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 600\n",
    "nombre_neurones_entree = 60\n",
    "nombre_neurones_sortie = 2\n",
    "taux_apprentissage = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variable TensorFLow correspondant aux 60 valeurs des neurones d'entrée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_neurones_entrees_X = tf.placeholder(tf.float32,[None, 60])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variable TensorFlow correspondant au 2 neurones de sortie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_valeurs_reelles_Y = tf.placeholder(tf.float32,[None, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "poids = {\n",
    "    # 60 neurones d'entrées vers 24 Neurones de la couche cachée\n",
    "    'couche_entree_vers_cachee': tf.Variable(tf.random_normal([60, 31]), tf.float32),\n",
    "\n",
    "    # 24 neurones de la couche cachée vers 2 de la couche de sortie\n",
    "    'couche_cachee_vers_sortie': tf.Variable(tf.random_normal([31, 2]), tf.float32),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "poids_biais = {\n",
    "     #1 biais de la couche d'entrée vers les 24 neurones de la couche cachée\n",
    "    'poids_biais_couche_entree_vers_cachee': tf.Variable(tf.zeros([31]), tf.float32),\n",
    "\n",
    "    #1 biais de la couche cachée vers les 2 neurones de la couche de sortie\n",
    "    'poids_biais_couche_cachee_vers_sortie': tf.Variable(tf.zeros([2]), tf.float32),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FONCTION DE  CREATION DU RESEAU DE NEURONES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reseau_neurones_multicouches(observations_en_entrees, poids, poids_biais):\n",
    "\n",
    "    #Calcul de l'activation de la première couche\n",
    "    premiere_activation = tf.sigmoid(tf.matmul(tf_neurones_entrees_X, poids['couche_entree_vers_cachee']) + poids_biais['poids_biais_couche_entree_vers_cachee'])\n",
    "\n",
    "    #Calcul de l'activation de la seconde couche\n",
    "    activation_couche_cachee = tf.sigmoid(tf.matmul(premiere_activation, poids['couche_cachee_vers_sortie']) + poids_biais['poids_biais_couche_cachee_vers_sortie'])\n",
    "\n",
    "    return activation_couche_cachee"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CREATION DU RESEAU DE NEURONES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "reseau = reseau_neurones_multicouches(tf_neurones_entrees_X, poids, poids_biais)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ERREUR ET OPTIMISATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fonction d'erreur de moyenne quadratique MSE\n",
    "fonction_erreur = tf.reduce_sum(tf.pow(tf_valeurs_reelles_Y-reseau,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Descente de gradient avec un taux d'apprentissage fixé à 0.1\n",
    "optimiseur = tf.train.GradientDescentOptimizer(learning_rate=taux_apprentissage).minimize(fonction_erreur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "### APPRENTISSAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialisation des variable\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Demarrage d'une session d'apprentissage\n",
    "session = tf.Session()\n",
    "session.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pour la réalisation du graphique pour la MSE\n",
    "Graphique_MSE=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH (0/600) -  MSE: 105.96817\n",
      "EPOCH (1/600) -  MSE: 94.91318\n",
      "EPOCH (2/600) -  MSE: 96.69737\n",
      "EPOCH (3/600) -  MSE: 107.22224\n",
      "EPOCH (4/600) -  MSE: 89.19901\n",
      "EPOCH (5/600) -  MSE: 102.93044\n",
      "EPOCH (6/600) -  MSE: 90.5025\n",
      "EPOCH (7/600) -  MSE: 106.05067\n",
      "EPOCH (8/600) -  MSE: 83.68471\n",
      "EPOCH (9/600) -  MSE: 99.52368\n",
      "EPOCH (10/600) -  MSE: 87.97502\n",
      "EPOCH (11/600) -  MSE: 104.258286\n",
      "EPOCH (12/600) -  MSE: 79.43183\n",
      "EPOCH (13/600) -  MSE: 94.841\n",
      "EPOCH (14/600) -  MSE: 86.79434\n",
      "EPOCH (15/600) -  MSE: 102.11151\n",
      "EPOCH (16/600) -  MSE: 76.28639\n",
      "EPOCH (17/600) -  MSE: 90.76884\n",
      "EPOCH (18/600) -  MSE: 84.99304\n",
      "EPOCH (19/600) -  MSE: 99.497154\n",
      "EPOCH (20/600) -  MSE: 74.30581\n",
      "EPOCH (21/600) -  MSE: 88.314835\n",
      "EPOCH (22/600) -  MSE: 82.28292\n",
      "EPOCH (23/600) -  MSE: 96.65588\n",
      "EPOCH (24/600) -  MSE: 72.995674\n",
      "EPOCH (25/600) -  MSE: 86.80003\n",
      "EPOCH (26/600) -  MSE: 79.44826\n",
      "EPOCH (27/600) -  MSE: 93.77419\n",
      "EPOCH (28/600) -  MSE: 72.03291\n",
      "EPOCH (29/600) -  MSE: 85.6861\n",
      "EPOCH (30/600) -  MSE: 76.76899\n",
      "EPOCH (31/600) -  MSE: 90.91731\n",
      "EPOCH (32/600) -  MSE: 71.25041\n",
      "EPOCH (33/600) -  MSE: 84.70024\n",
      "EPOCH (34/600) -  MSE: 74.33681\n",
      "EPOCH (35/600) -  MSE: 88.13851\n",
      "EPOCH (36/600) -  MSE: 70.51947\n",
      "EPOCH (37/600) -  MSE: 83.67488\n",
      "EPOCH (38/600) -  MSE: 72.20241\n",
      "EPOCH (39/600) -  MSE: 85.522255\n",
      "EPOCH (40/600) -  MSE: 69.73341\n",
      "EPOCH (41/600) -  MSE: 82.507614\n",
      "EPOCH (42/600) -  MSE: 70.38105\n",
      "EPOCH (43/600) -  MSE: 83.14783\n",
      "EPOCH (44/600) -  MSE: 68.83943\n",
      "EPOCH (45/600) -  MSE: 81.16929\n",
      "EPOCH (46/600) -  MSE: 68.841446\n",
      "EPOCH (47/600) -  MSE: 81.03938\n",
      "EPOCH (48/600) -  MSE: 67.84891\n",
      "EPOCH (49/600) -  MSE: 79.696\n",
      "EPOCH (50/600) -  MSE: 67.519196\n",
      "EPOCH (51/600) -  MSE: 79.16237\n",
      "EPOCH (52/600) -  MSE: 66.80859\n",
      "EPOCH (53/600) -  MSE: 78.1562\n",
      "EPOCH (54/600) -  MSE: 66.345566\n",
      "EPOCH (55/600) -  MSE: 77.459305\n",
      "EPOCH (56/600) -  MSE: 65.76536\n",
      "EPOCH (57/600) -  MSE: 76.616776\n",
      "EPOCH (58/600) -  MSE: 65.26908\n",
      "EPOCH (59/600) -  MSE: 75.88379\n",
      "EPOCH (60/600) -  MSE: 64.74955\n",
      "EPOCH (61/600) -  MSE: 75.1254\n",
      "EPOCH (62/600) -  MSE: 64.26048\n",
      "EPOCH (63/600) -  MSE: 74.41148\n",
      "EPOCH (64/600) -  MSE: 63.775616\n",
      "EPOCH (65/600) -  MSE: 73.70917\n",
      "EPOCH (66/600) -  MSE: 63.30681\n",
      "EPOCH (67/600) -  MSE: 73.03446\n",
      "EPOCH (68/600) -  MSE: 62.84874\n",
      "EPOCH (69/600) -  MSE: 72.38081\n",
      "EPOCH (70/600) -  MSE: 62.403465\n",
      "EPOCH (71/600) -  MSE: 71.75121\n",
      "EPOCH (72/600) -  MSE: 61.970043\n",
      "EPOCH (73/600) -  MSE: 71.144424\n",
      "EPOCH (74/600) -  MSE: 61.54867\n",
      "EPOCH (75/600) -  MSE: 70.56051\n",
      "EPOCH (76/600) -  MSE: 61.139046\n",
      "EPOCH (77/600) -  MSE: 69.998856\n",
      "EPOCH (78/600) -  MSE: 60.740967\n",
      "EPOCH (79/600) -  MSE: 69.4588\n",
      "EPOCH (80/600) -  MSE: 60.354176\n",
      "EPOCH (81/600) -  MSE: 68.939575\n",
      "EPOCH (82/600) -  MSE: 59.97827\n",
      "EPOCH (83/600) -  MSE: 68.44027\n",
      "EPOCH (84/600) -  MSE: 59.612976\n",
      "EPOCH (85/600) -  MSE: 67.95997\n",
      "EPOCH (86/600) -  MSE: 59.257828\n",
      "EPOCH (87/600) -  MSE: 67.497665\n",
      "EPOCH (88/600) -  MSE: 58.912407\n",
      "EPOCH (89/600) -  MSE: 67.052345\n",
      "EPOCH (90/600) -  MSE: 58.576286\n",
      "EPOCH (91/600) -  MSE: 66.62306\n",
      "EPOCH (92/600) -  MSE: 58.249004\n",
      "EPOCH (93/600) -  MSE: 66.20885\n",
      "EPOCH (94/600) -  MSE: 57.9301\n",
      "EPOCH (95/600) -  MSE: 65.80875\n",
      "EPOCH (96/600) -  MSE: 57.619164\n",
      "EPOCH (97/600) -  MSE: 65.421936\n",
      "EPOCH (98/600) -  MSE: 57.315704\n",
      "EPOCH (99/600) -  MSE: 65.0475\n",
      "EPOCH (100/600) -  MSE: 57.019325\n",
      "EPOCH (101/600) -  MSE: 64.6847\n",
      "EPOCH (102/600) -  MSE: 56.72959\n",
      "EPOCH (103/600) -  MSE: 64.33272\n",
      "EPOCH (104/600) -  MSE: 56.446117\n",
      "EPOCH (105/600) -  MSE: 63.9909\n",
      "EPOCH (106/600) -  MSE: 56.168495\n",
      "EPOCH (107/600) -  MSE: 63.65854\n",
      "EPOCH (108/600) -  MSE: 55.89637\n",
      "EPOCH (109/600) -  MSE: 63.334988\n",
      "EPOCH (110/600) -  MSE: 55.629387\n",
      "EPOCH (111/600) -  MSE: 63.01969\n",
      "EPOCH (112/600) -  MSE: 55.36719\n",
      "EPOCH (113/600) -  MSE: 62.71203\n",
      "EPOCH (114/600) -  MSE: 55.109493\n",
      "EPOCH (115/600) -  MSE: 62.411507\n",
      "EPOCH (116/600) -  MSE: 54.855965\n",
      "EPOCH (117/600) -  MSE: 62.117588\n",
      "EPOCH (118/600) -  MSE: 54.60634\n",
      "EPOCH (119/600) -  MSE: 61.829807\n",
      "EPOCH (120/600) -  MSE: 54.36033\n",
      "EPOCH (121/600) -  MSE: 61.54769\n",
      "EPOCH (122/600) -  MSE: 54.117702\n",
      "EPOCH (123/600) -  MSE: 61.270832\n",
      "EPOCH (124/600) -  MSE: 53.878223\n",
      "EPOCH (125/600) -  MSE: 60.9988\n",
      "EPOCH (126/600) -  MSE: 53.641647\n",
      "EPOCH (127/600) -  MSE: 60.731186\n",
      "EPOCH (128/600) -  MSE: 53.407806\n",
      "EPOCH (129/600) -  MSE: 60.46766\n",
      "EPOCH (130/600) -  MSE: 53.176495\n",
      "EPOCH (131/600) -  MSE: 60.20788\n",
      "EPOCH (132/600) -  MSE: 52.947556\n",
      "EPOCH (133/600) -  MSE: 59.951504\n",
      "EPOCH (134/600) -  MSE: 52.720825\n",
      "EPOCH (135/600) -  MSE: 59.698235\n",
      "EPOCH (136/600) -  MSE: 52.49615\n",
      "EPOCH (137/600) -  MSE: 59.44783\n",
      "EPOCH (138/600) -  MSE: 52.273422\n",
      "EPOCH (139/600) -  MSE: 59.20003\n",
      "EPOCH (140/600) -  MSE: 52.05252\n",
      "EPOCH (141/600) -  MSE: 58.954582\n",
      "EPOCH (142/600) -  MSE: 51.83333\n",
      "EPOCH (143/600) -  MSE: 58.711304\n",
      "EPOCH (144/600) -  MSE: 51.61577\n",
      "EPOCH (145/600) -  MSE: 58.470024\n",
      "EPOCH (146/600) -  MSE: 51.399754\n",
      "EPOCH (147/600) -  MSE: 58.230583\n",
      "EPOCH (148/600) -  MSE: 51.185204\n",
      "EPOCH (149/600) -  MSE: 57.99282\n",
      "EPOCH (150/600) -  MSE: 50.97206\n",
      "EPOCH (151/600) -  MSE: 57.75663\n",
      "EPOCH (152/600) -  MSE: 50.760265\n",
      "EPOCH (153/600) -  MSE: 57.521904\n",
      "EPOCH (154/600) -  MSE: 50.549774\n",
      "EPOCH (155/600) -  MSE: 57.28855\n",
      "EPOCH (156/600) -  MSE: 50.340523\n",
      "EPOCH (157/600) -  MSE: 57.05652\n",
      "EPOCH (158/600) -  MSE: 50.13249\n",
      "EPOCH (159/600) -  MSE: 56.82573\n",
      "EPOCH (160/600) -  MSE: 49.925632\n",
      "EPOCH (161/600) -  MSE: 56.596153\n",
      "EPOCH (162/600) -  MSE: 49.719906\n",
      "EPOCH (163/600) -  MSE: 56.367683\n",
      "EPOCH (164/600) -  MSE: 49.515312\n",
      "EPOCH (165/600) -  MSE: 56.14039\n",
      "EPOCH (166/600) -  MSE: 49.3118\n",
      "EPOCH (167/600) -  MSE: 55.914192\n",
      "EPOCH (168/600) -  MSE: 49.10934\n",
      "EPOCH (169/600) -  MSE: 55.68904\n",
      "EPOCH (170/600) -  MSE: 48.907936\n",
      "EPOCH (171/600) -  MSE: 55.464973\n",
      "EPOCH (172/600) -  MSE: 48.707558\n",
      "EPOCH (173/600) -  MSE: 55.24195\n",
      "EPOCH (174/600) -  MSE: 48.50818\n",
      "EPOCH (175/600) -  MSE: 55.019962\n",
      "EPOCH (176/600) -  MSE: 48.30979\n",
      "EPOCH (177/600) -  MSE: 54.79899\n",
      "EPOCH (178/600) -  MSE: 48.112373\n",
      "EPOCH (179/600) -  MSE: 54.579033\n",
      "EPOCH (180/600) -  MSE: 47.9159\n",
      "EPOCH (181/600) -  MSE: 54.360073\n",
      "EPOCH (182/600) -  MSE: 47.720375\n",
      "EPOCH (183/600) -  MSE: 54.142094\n",
      "EPOCH (184/600) -  MSE: 47.525772\n",
      "EPOCH (185/600) -  MSE: 53.925114\n",
      "EPOCH (186/600) -  MSE: 47.332085\n",
      "EPOCH (187/600) -  MSE: 53.709084\n",
      "EPOCH (188/600) -  MSE: 47.13929\n",
      "EPOCH (189/600) -  MSE: 53.494003\n",
      "EPOCH (190/600) -  MSE: 46.94738\n",
      "EPOCH (191/600) -  MSE: 53.27986\n",
      "EPOCH (192/600) -  MSE: 46.75634\n",
      "EPOCH (193/600) -  MSE: 53.06664\n",
      "EPOCH (194/600) -  MSE: 46.566174\n",
      "EPOCH (195/600) -  MSE: 52.854336\n",
      "EPOCH (196/600) -  MSE: 46.37685\n",
      "EPOCH (197/600) -  MSE: 52.642902\n",
      "EPOCH (198/600) -  MSE: 46.188362\n",
      "EPOCH (199/600) -  MSE: 52.432346\n",
      "EPOCH (200/600) -  MSE: 46.000694\n",
      "EPOCH (201/600) -  MSE: 52.222626\n",
      "EPOCH (202/600) -  MSE: 45.81385\n",
      "EPOCH (203/600) -  MSE: 52.013744\n",
      "EPOCH (204/600) -  MSE: 45.627815\n",
      "EPOCH (205/600) -  MSE: 51.80566\n",
      "EPOCH (206/600) -  MSE: 45.442562\n",
      "EPOCH (207/600) -  MSE: 51.598373\n",
      "EPOCH (208/600) -  MSE: 45.25811\n",
      "EPOCH (209/600) -  MSE: 51.39184\n",
      "EPOCH (210/600) -  MSE: 45.07444\n",
      "EPOCH (211/600) -  MSE: 51.18607\n",
      "EPOCH (212/600) -  MSE: 44.891533\n",
      "EPOCH (213/600) -  MSE: 50.981014\n",
      "EPOCH (214/600) -  MSE: 44.70939\n",
      "EPOCH (215/600) -  MSE: 50.77664\n",
      "EPOCH (216/600) -  MSE: 44.527996\n",
      "EPOCH (217/600) -  MSE: 50.57296\n",
      "EPOCH (218/600) -  MSE: 44.34735\n",
      "EPOCH (219/600) -  MSE: 50.369934\n",
      "EPOCH (220/600) -  MSE: 44.167446\n",
      "EPOCH (221/600) -  MSE: 50.167553\n",
      "EPOCH (222/600) -  MSE: 43.988266\n",
      "EPOCH (223/600) -  MSE: 49.965775\n",
      "EPOCH (224/600) -  MSE: 43.809822\n",
      "EPOCH (225/600) -  MSE: 49.764587\n",
      "EPOCH (226/600) -  MSE: 43.6321\n",
      "EPOCH (227/600) -  MSE: 49.56399\n",
      "EPOCH (228/600) -  MSE: 43.455086\n",
      "EPOCH (229/600) -  MSE: 49.36395\n",
      "EPOCH (230/600) -  MSE: 43.278786\n",
      "EPOCH (231/600) -  MSE: 49.16445\n",
      "EPOCH (232/600) -  MSE: 43.103176\n",
      "EPOCH (233/600) -  MSE: 48.96547\n",
      "EPOCH (234/600) -  MSE: 42.928272\n",
      "EPOCH (235/600) -  MSE: 48.766983\n",
      "EPOCH (236/600) -  MSE: 42.75405\n",
      "EPOCH (237/600) -  MSE: 48.569016\n",
      "EPOCH (238/600) -  MSE: 42.58053\n",
      "EPOCH (239/600) -  MSE: 48.371513\n",
      "EPOCH (240/600) -  MSE: 42.407692\n",
      "EPOCH (241/600) -  MSE: 48.17447\n",
      "EPOCH (242/600) -  MSE: 42.235527\n",
      "EPOCH (243/600) -  MSE: 47.977882\n",
      "EPOCH (244/600) -  MSE: 42.06404\n",
      "EPOCH (245/600) -  MSE: 47.78173\n",
      "EPOCH (246/600) -  MSE: 41.893223\n",
      "EPOCH (247/600) -  MSE: 47.586014\n",
      "EPOCH (248/600) -  MSE: 41.723072\n",
      "EPOCH (249/600) -  MSE: 47.39073\n",
      "EPOCH (250/600) -  MSE: 41.553596\n",
      "EPOCH (251/600) -  MSE: 47.195854\n",
      "EPOCH (252/600) -  MSE: 41.384773\n",
      "EPOCH (253/600) -  MSE: 47.00138\n",
      "EPOCH (254/600) -  MSE: 41.216618\n",
      "EPOCH (255/600) -  MSE: 46.807304\n",
      "EPOCH (256/600) -  MSE: 41.049118\n",
      "EPOCH (257/600) -  MSE: 46.61365\n",
      "EPOCH (258/600) -  MSE: 40.882263\n",
      "EPOCH (259/600) -  MSE: 46.420364\n",
      "EPOCH (260/600) -  MSE: 40.716057\n",
      "EPOCH (261/600) -  MSE: 46.227463\n",
      "EPOCH (262/600) -  MSE: 40.550503\n",
      "EPOCH (263/600) -  MSE: 46.03497\n",
      "EPOCH (264/600) -  MSE: 40.385605\n",
      "EPOCH (265/600) -  MSE: 45.842865\n",
      "EPOCH (266/600) -  MSE: 40.22135\n",
      "EPOCH (267/600) -  MSE: 45.651142\n",
      "EPOCH (268/600) -  MSE: 40.05774\n",
      "EPOCH (269/600) -  MSE: 45.459835\n",
      "EPOCH (270/600) -  MSE: 39.894775\n",
      "EPOCH (271/600) -  MSE: 45.268898\n",
      "EPOCH (272/600) -  MSE: 39.732445\n",
      "EPOCH (273/600) -  MSE: 45.078365\n",
      "EPOCH (274/600) -  MSE: 39.57076\n",
      "EPOCH (275/600) -  MSE: 44.888237\n",
      "EPOCH (276/600) -  MSE: 39.409718\n",
      "EPOCH (277/600) -  MSE: 44.69852\n",
      "EPOCH (278/600) -  MSE: 39.249313\n",
      "EPOCH (279/600) -  MSE: 44.509216\n",
      "EPOCH (280/600) -  MSE: 39.089546\n",
      "EPOCH (281/600) -  MSE: 44.320328\n",
      "EPOCH (282/600) -  MSE: 38.930428\n",
      "EPOCH (283/600) -  MSE: 44.131893\n",
      "EPOCH (284/600) -  MSE: 38.771942\n",
      "EPOCH (285/600) -  MSE: 43.94387\n",
      "EPOCH (286/600) -  MSE: 38.614098\n",
      "EPOCH (287/600) -  MSE: 43.756313\n",
      "EPOCH (288/600) -  MSE: 38.456894\n",
      "EPOCH (289/600) -  MSE: 43.569214\n",
      "EPOCH (290/600) -  MSE: 38.300343\n",
      "EPOCH (291/600) -  MSE: 43.3826\n",
      "EPOCH (292/600) -  MSE: 38.144424\n",
      "EPOCH (293/600) -  MSE: 43.196465\n",
      "EPOCH (294/600) -  MSE: 37.98915\n",
      "EPOCH (295/600) -  MSE: 43.010826\n",
      "EPOCH (296/600) -  MSE: 37.834534\n",
      "EPOCH (297/600) -  MSE: 42.82569\n",
      "EPOCH (298/600) -  MSE: 37.68056\n",
      "EPOCH (299/600) -  MSE: 42.641106\n",
      "EPOCH (300/600) -  MSE: 37.527245\n",
      "EPOCH (301/600) -  MSE: 42.457047\n",
      "EPOCH (302/600) -  MSE: 37.37458\n",
      "EPOCH (303/600) -  MSE: 42.27355\n",
      "EPOCH (304/600) -  MSE: 37.222572\n",
      "EPOCH (305/600) -  MSE: 42.090622\n",
      "EPOCH (306/600) -  MSE: 37.071228\n",
      "EPOCH (307/600) -  MSE: 41.908302\n",
      "EPOCH (308/600) -  MSE: 36.920544\n",
      "EPOCH (309/600) -  MSE: 41.726578\n",
      "EPOCH (310/600) -  MSE: 36.77053\n",
      "EPOCH (311/600) -  MSE: 41.545464\n",
      "EPOCH (312/600) -  MSE: 36.621185\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH (313/600) -  MSE: 41.365017\n",
      "EPOCH (314/600) -  MSE: 36.47252\n",
      "EPOCH (315/600) -  MSE: 41.185226\n",
      "EPOCH (316/600) -  MSE: 36.32453\n",
      "EPOCH (317/600) -  MSE: 41.006115\n",
      "EPOCH (318/600) -  MSE: 36.177227\n",
      "EPOCH (319/600) -  MSE: 40.827705\n",
      "EPOCH (320/600) -  MSE: 36.03061\n",
      "EPOCH (321/600) -  MSE: 40.65001\n",
      "EPOCH (322/600) -  MSE: 35.88468\n",
      "EPOCH (323/600) -  MSE: 40.473053\n",
      "EPOCH (324/600) -  MSE: 35.739456\n",
      "EPOCH (325/600) -  MSE: 40.296852\n",
      "EPOCH (326/600) -  MSE: 35.594936\n",
      "EPOCH (327/600) -  MSE: 40.12143\n",
      "EPOCH (328/600) -  MSE: 35.45112\n",
      "EPOCH (329/600) -  MSE: 39.946793\n",
      "EPOCH (330/600) -  MSE: 35.30801\n",
      "EPOCH (331/600) -  MSE: 39.77296\n",
      "EPOCH (332/600) -  MSE: 35.165615\n",
      "EPOCH (333/600) -  MSE: 39.599964\n",
      "EPOCH (334/600) -  MSE: 35.02395\n",
      "EPOCH (335/600) -  MSE: 39.427826\n",
      "EPOCH (336/600) -  MSE: 34.883003\n",
      "EPOCH (337/600) -  MSE: 39.256546\n",
      "EPOCH (338/600) -  MSE: 34.7428\n",
      "EPOCH (339/600) -  MSE: 39.08615\n",
      "EPOCH (340/600) -  MSE: 34.603325\n",
      "EPOCH (341/600) -  MSE: 38.91666\n",
      "EPOCH (342/600) -  MSE: 34.464584\n",
      "EPOCH (343/600) -  MSE: 38.748085\n",
      "EPOCH (344/600) -  MSE: 34.32659\n",
      "EPOCH (345/600) -  MSE: 38.58044\n",
      "EPOCH (346/600) -  MSE: 34.189335\n",
      "EPOCH (347/600) -  MSE: 38.41375\n",
      "EPOCH (348/600) -  MSE: 34.05284\n",
      "EPOCH (349/600) -  MSE: 38.24802\n",
      "EPOCH (350/600) -  MSE: 33.91709\n",
      "EPOCH (351/600) -  MSE: 38.083267\n",
      "EPOCH (352/600) -  MSE: 33.78212\n",
      "EPOCH (353/600) -  MSE: 37.919514\n",
      "EPOCH (354/600) -  MSE: 33.647896\n",
      "EPOCH (355/600) -  MSE: 37.756767\n",
      "EPOCH (356/600) -  MSE: 33.514442\n",
      "EPOCH (357/600) -  MSE: 37.59505\n",
      "EPOCH (358/600) -  MSE: 33.381744\n",
      "EPOCH (359/600) -  MSE: 37.43435\n",
      "EPOCH (360/600) -  MSE: 33.24982\n",
      "EPOCH (361/600) -  MSE: 37.27468\n",
      "EPOCH (362/600) -  MSE: 33.118668\n",
      "EPOCH (363/600) -  MSE: 37.11609\n",
      "EPOCH (364/600) -  MSE: 32.988285\n",
      "EPOCH (365/600) -  MSE: 36.958538\n",
      "EPOCH (366/600) -  MSE: 32.858665\n",
      "EPOCH (367/600) -  MSE: 36.80206\n",
      "EPOCH (368/600) -  MSE: 32.729836\n",
      "EPOCH (369/600) -  MSE: 36.646675\n",
      "EPOCH (370/600) -  MSE: 32.601776\n",
      "EPOCH (371/600) -  MSE: 36.492367\n",
      "EPOCH (372/600) -  MSE: 32.474487\n",
      "EPOCH (373/600) -  MSE: 36.33915\n",
      "EPOCH (374/600) -  MSE: 32.34797\n",
      "EPOCH (375/600) -  MSE: 36.187027\n",
      "EPOCH (376/600) -  MSE: 32.222237\n",
      "EPOCH (377/600) -  MSE: 36.03602\n",
      "EPOCH (378/600) -  MSE: 32.09727\n",
      "EPOCH (379/600) -  MSE: 35.88611\n",
      "EPOCH (380/600) -  MSE: 31.97308\n",
      "EPOCH (381/600) -  MSE: 35.73731\n",
      "EPOCH (382/600) -  MSE: 31.849659\n",
      "EPOCH (383/600) -  MSE: 35.58963\n",
      "EPOCH (384/600) -  MSE: 31.727\n",
      "EPOCH (385/600) -  MSE: 35.44305\n",
      "EPOCH (386/600) -  MSE: 31.605122\n",
      "EPOCH (387/600) -  MSE: 35.2976\n",
      "EPOCH (388/600) -  MSE: 31.484013\n",
      "EPOCH (389/600) -  MSE: 35.153267\n",
      "EPOCH (390/600) -  MSE: 31.36365\n",
      "EPOCH (391/600) -  MSE: 35.010036\n",
      "EPOCH (392/600) -  MSE: 31.244053\n",
      "EPOCH (393/600) -  MSE: 34.86792\n",
      "EPOCH (394/600) -  MSE: 31.125214\n",
      "EPOCH (395/600) -  MSE: 34.72693\n",
      "EPOCH (396/600) -  MSE: 31.007133\n",
      "EPOCH (397/600) -  MSE: 34.587044\n",
      "EPOCH (398/600) -  MSE: 30.889797\n",
      "EPOCH (399/600) -  MSE: 34.448265\n",
      "EPOCH (400/600) -  MSE: 30.773201\n",
      "EPOCH (401/600) -  MSE: 34.31057\n",
      "EPOCH (402/600) -  MSE: 30.65735\n",
      "EPOCH (403/600) -  MSE: 34.173996\n",
      "EPOCH (404/600) -  MSE: 30.542236\n",
      "EPOCH (405/600) -  MSE: 34.038506\n",
      "EPOCH (406/600) -  MSE: 30.427853\n",
      "EPOCH (407/600) -  MSE: 33.904102\n",
      "EPOCH (408/600) -  MSE: 30.314198\n",
      "EPOCH (409/600) -  MSE: 33.77077\n",
      "EPOCH (410/600) -  MSE: 30.201271\n",
      "EPOCH (411/600) -  MSE: 33.63852\n",
      "EPOCH (412/600) -  MSE: 30.08905\n",
      "EPOCH (413/600) -  MSE: 33.507324\n",
      "EPOCH (414/600) -  MSE: 29.977541\n",
      "EPOCH (415/600) -  MSE: 33.377186\n",
      "EPOCH (416/600) -  MSE: 29.866734\n",
      "EPOCH (417/600) -  MSE: 33.248096\n",
      "EPOCH (418/600) -  MSE: 29.756626\n",
      "EPOCH (419/600) -  MSE: 33.120045\n",
      "EPOCH (420/600) -  MSE: 29.647217\n",
      "EPOCH (421/600) -  MSE: 32.99303\n",
      "EPOCH (422/600) -  MSE: 29.538486\n",
      "EPOCH (423/600) -  MSE: 32.867012\n",
      "EPOCH (424/600) -  MSE: 29.430431\n",
      "EPOCH (425/600) -  MSE: 32.742012\n",
      "EPOCH (426/600) -  MSE: 29.32305\n",
      "EPOCH (427/600) -  MSE: 32.618004\n",
      "EPOCH (428/600) -  MSE: 29.216324\n",
      "EPOCH (429/600) -  MSE: 32.49497\n",
      "EPOCH (430/600) -  MSE: 29.110252\n",
      "EPOCH (431/600) -  MSE: 32.3729\n",
      "EPOCH (432/600) -  MSE: 29.004839\n",
      "EPOCH (433/600) -  MSE: 32.25179\n",
      "EPOCH (434/600) -  MSE: 28.900053\n",
      "EPOCH (435/600) -  MSE: 32.131607\n",
      "EPOCH (436/600) -  MSE: 28.795906\n",
      "EPOCH (437/600) -  MSE: 32.01236\n",
      "EPOCH (438/600) -  MSE: 28.692375\n",
      "EPOCH (439/600) -  MSE: 31.89402\n",
      "EPOCH (440/600) -  MSE: 28.589464\n",
      "EPOCH (441/600) -  MSE: 31.776579\n",
      "EPOCH (442/600) -  MSE: 28.487156\n",
      "EPOCH (443/600) -  MSE: 31.660013\n",
      "EPOCH (444/600) -  MSE: 28.385448\n",
      "EPOCH (445/600) -  MSE: 31.544315\n",
      "EPOCH (446/600) -  MSE: 28.284319\n",
      "EPOCH (447/600) -  MSE: 31.429466\n",
      "EPOCH (448/600) -  MSE: 28.183767\n",
      "EPOCH (449/600) -  MSE: 31.315437\n",
      "EPOCH (450/600) -  MSE: 28.08379\n",
      "EPOCH (451/600) -  MSE: 31.202229\n",
      "EPOCH (452/600) -  MSE: 27.984373\n",
      "EPOCH (453/600) -  MSE: 31.089823\n",
      "EPOCH (454/600) -  MSE: 27.88551\n",
      "EPOCH (455/600) -  MSE: 30.978195\n",
      "EPOCH (456/600) -  MSE: 27.78717\n",
      "EPOCH (457/600) -  MSE: 30.86731\n",
      "EPOCH (458/600) -  MSE: 27.689363\n",
      "EPOCH (459/600) -  MSE: 30.75717\n",
      "EPOCH (460/600) -  MSE: 27.592083\n",
      "EPOCH (461/600) -  MSE: 30.647766\n",
      "EPOCH (462/600) -  MSE: 27.495304\n",
      "EPOCH (463/600) -  MSE: 30.539059\n",
      "EPOCH (464/600) -  MSE: 27.39904\n",
      "EPOCH (465/600) -  MSE: 30.431047\n",
      "EPOCH (466/600) -  MSE: 27.303255\n",
      "EPOCH (467/600) -  MSE: 30.3237\n",
      "EPOCH (468/600) -  MSE: 27.207945\n",
      "EPOCH (469/600) -  MSE: 30.216991\n",
      "EPOCH (470/600) -  MSE: 27.113106\n",
      "EPOCH (471/600) -  MSE: 30.11091\n",
      "EPOCH (472/600) -  MSE: 27.018719\n",
      "EPOCH (473/600) -  MSE: 30.005444\n",
      "EPOCH (474/600) -  MSE: 26.924786\n",
      "EPOCH (475/600) -  MSE: 29.900562\n",
      "EPOCH (476/600) -  MSE: 26.831291\n",
      "EPOCH (477/600) -  MSE: 29.796257\n",
      "EPOCH (478/600) -  MSE: 26.738222\n",
      "EPOCH (479/600) -  MSE: 29.692503\n",
      "EPOCH (480/600) -  MSE: 26.645569\n",
      "EPOCH (481/600) -  MSE: 29.589283\n",
      "EPOCH (482/600) -  MSE: 26.553314\n",
      "EPOCH (483/600) -  MSE: 29.48656\n",
      "EPOCH (484/600) -  MSE: 26.46146\n",
      "EPOCH (485/600) -  MSE: 29.384344\n",
      "EPOCH (486/600) -  MSE: 26.369987\n",
      "EPOCH (487/600) -  MSE: 29.282593\n",
      "EPOCH (488/600) -  MSE: 26.278885\n",
      "EPOCH (489/600) -  MSE: 29.181293\n",
      "EPOCH (490/600) -  MSE: 26.188152\n",
      "EPOCH (491/600) -  MSE: 29.080425\n",
      "EPOCH (492/600) -  MSE: 26.097763\n",
      "EPOCH (493/600) -  MSE: 28.979977\n",
      "EPOCH (494/600) -  MSE: 26.00773\n",
      "EPOCH (495/600) -  MSE: 28.879923\n",
      "EPOCH (496/600) -  MSE: 25.918016\n",
      "EPOCH (497/600) -  MSE: 28.780243\n",
      "EPOCH (498/600) -  MSE: 25.828623\n",
      "EPOCH (499/600) -  MSE: 28.680904\n",
      "EPOCH (500/600) -  MSE: 25.73955\n",
      "EPOCH (501/600) -  MSE: 28.581934\n",
      "EPOCH (502/600) -  MSE: 25.650768\n",
      "EPOCH (503/600) -  MSE: 28.48327\n",
      "EPOCH (504/600) -  MSE: 25.56228\n",
      "EPOCH (505/600) -  MSE: 28.38491\n",
      "EPOCH (506/600) -  MSE: 25.474075\n",
      "EPOCH (507/600) -  MSE: 28.286835\n",
      "EPOCH (508/600) -  MSE: 25.386147\n",
      "EPOCH (509/600) -  MSE: 28.18904\n",
      "EPOCH (510/600) -  MSE: 25.29847\n",
      "EPOCH (511/600) -  MSE: 28.091473\n",
      "EPOCH (512/600) -  MSE: 25.211042\n",
      "EPOCH (513/600) -  MSE: 27.994143\n",
      "EPOCH (514/600) -  MSE: 25.123867\n",
      "EPOCH (515/600) -  MSE: 27.897032\n",
      "EPOCH (516/600) -  MSE: 25.036926\n",
      "EPOCH (517/600) -  MSE: 27.800125\n",
      "EPOCH (518/600) -  MSE: 24.950195\n",
      "EPOCH (519/600) -  MSE: 27.7034\n",
      "EPOCH (520/600) -  MSE: 24.863682\n",
      "EPOCH (521/600) -  MSE: 27.606842\n",
      "EPOCH (522/600) -  MSE: 24.777382\n",
      "EPOCH (523/600) -  MSE: 27.510445\n",
      "EPOCH (524/600) -  MSE: 24.691286\n",
      "EPOCH (525/600) -  MSE: 27.414188\n",
      "EPOCH (526/600) -  MSE: 24.605373\n",
      "EPOCH (527/600) -  MSE: 27.318058\n",
      "EPOCH (528/600) -  MSE: 24.519644\n",
      "EPOCH (529/600) -  MSE: 27.222034\n",
      "EPOCH (530/600) -  MSE: 24.43408\n",
      "EPOCH (531/600) -  MSE: 27.126116\n",
      "EPOCH (532/600) -  MSE: 24.348686\n",
      "EPOCH (533/600) -  MSE: 27.030275\n",
      "EPOCH (534/600) -  MSE: 24.263447\n",
      "EPOCH (535/600) -  MSE: 26.93451\n",
      "EPOCH (536/600) -  MSE: 24.17836\n",
      "EPOCH (537/600) -  MSE: 26.838806\n",
      "EPOCH (538/600) -  MSE: 24.09342\n",
      "EPOCH (539/600) -  MSE: 26.743149\n",
      "EPOCH (540/600) -  MSE: 24.008612\n",
      "EPOCH (541/600) -  MSE: 26.64754\n",
      "EPOCH (542/600) -  MSE: 23.923939\n",
      "EPOCH (543/600) -  MSE: 26.55195\n",
      "EPOCH (544/600) -  MSE: 23.839378\n",
      "EPOCH (545/600) -  MSE: 26.456379\n",
      "EPOCH (546/600) -  MSE: 23.75493\n",
      "EPOCH (547/600) -  MSE: 26.360813\n",
      "EPOCH (548/600) -  MSE: 23.670607\n",
      "EPOCH (549/600) -  MSE: 26.265253\n",
      "EPOCH (550/600) -  MSE: 23.58638\n",
      "EPOCH (551/600) -  MSE: 26.169685\n",
      "EPOCH (552/600) -  MSE: 23.502254\n",
      "EPOCH (553/600) -  MSE: 26.074104\n",
      "EPOCH (554/600) -  MSE: 23.41823\n",
      "EPOCH (555/600) -  MSE: 25.978508\n",
      "EPOCH (556/600) -  MSE: 23.33428\n",
      "EPOCH (557/600) -  MSE: 25.882858\n",
      "EPOCH (558/600) -  MSE: 23.25042\n",
      "EPOCH (559/600) -  MSE: 25.787178\n",
      "EPOCH (560/600) -  MSE: 23.166641\n",
      "EPOCH (561/600) -  MSE: 25.691458\n",
      "EPOCH (562/600) -  MSE: 23.082941\n",
      "EPOCH (563/600) -  MSE: 25.595695\n",
      "EPOCH (564/600) -  MSE: 22.999308\n",
      "EPOCH (565/600) -  MSE: 25.499882\n",
      "EPOCH (566/600) -  MSE: 22.915737\n",
      "EPOCH (567/600) -  MSE: 25.403996\n",
      "EPOCH (568/600) -  MSE: 22.832235\n",
      "EPOCH (569/600) -  MSE: 25.308064\n",
      "EPOCH (570/600) -  MSE: 22.748802\n",
      "EPOCH (571/600) -  MSE: 25.21207\n",
      "EPOCH (572/600) -  MSE: 22.665417\n",
      "EPOCH (573/600) -  MSE: 25.116003\n",
      "EPOCH (574/600) -  MSE: 22.582096\n",
      "EPOCH (575/600) -  MSE: 25.01987\n",
      "EPOCH (576/600) -  MSE: 22.498821\n",
      "EPOCH (577/600) -  MSE: 24.923666\n",
      "EPOCH (578/600) -  MSE: 22.415604\n",
      "EPOCH (579/600) -  MSE: 24.82739\n",
      "EPOCH (580/600) -  MSE: 22.33243\n",
      "EPOCH (581/600) -  MSE: 24.731047\n",
      "EPOCH (582/600) -  MSE: 22.249306\n",
      "EPOCH (583/600) -  MSE: 24.634628\n",
      "EPOCH (584/600) -  MSE: 22.166233\n",
      "EPOCH (585/600) -  MSE: 24.538143\n",
      "EPOCH (586/600) -  MSE: 22.083199\n",
      "EPOCH (587/600) -  MSE: 24.44159\n",
      "EPOCH (588/600) -  MSE: 22.00021\n",
      "EPOCH (589/600) -  MSE: 24.34496\n",
      "EPOCH (590/600) -  MSE: 21.917273\n",
      "EPOCH (591/600) -  MSE: 24.248264\n",
      "EPOCH (592/600) -  MSE: 21.834381\n",
      "EPOCH (593/600) -  MSE: 24.151516\n",
      "EPOCH (594/600) -  MSE: 21.751526\n",
      "EPOCH (595/600) -  MSE: 24.054695\n",
      "EPOCH (596/600) -  MSE: 21.668718\n",
      "EPOCH (597/600) -  MSE: 23.957811\n",
      "EPOCH (598/600) -  MSE: 21.58596\n",
      "EPOCH (599/600) -  MSE: 23.860878\n"
     ]
    }
   ],
   "source": [
    "#Pour chaque epoch\n",
    "for i in range(epochs):\n",
    "\n",
    "   #Realisation de l'apprentissage avec mise à jour des poids\n",
    "   session.run(optimiseur, feed_dict = {tf_neurones_entrees_X: train_x, tf_valeurs_reelles_Y:train_y})\n",
    "\n",
    "   #Calculer l'erreur\n",
    "   MSE = session.run(fonction_erreur, feed_dict = {tf_neurones_entrees_X: train_x, tf_valeurs_reelles_Y:train_y})\n",
    "\n",
    "   #Affichage des informations\n",
    "   Graphique_MSE.append(MSE)\n",
    "   print(\"EPOCH (\" + str(i) + \"/\" + str(epochs) + \") -  MSE: \"+ str(MSE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAD4CAYAAAAD6PrjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXwV9b3/8deHhAABQlhCgIQQQDAgQoC4IK6AFlHEulUftkVrL7ettS69bdHeLtr602vde6ut12ptte7WXSsi4s6+b2GHsCRhDfuSfH9/nEkMcJKQ5Jwz52Tez8cjj5yZM2fm88WYd2a+M9+vOecQEREBaOZ3ASIiEj8UCiIiUkWhICIiVRQKIiJSRaEgIiJVkv0uoDE6derkcnNz/S5DRCShzJo1a4tzLiPcewkdCrm5ucycOdPvMkREEoqZra3pPV0+EhGRKgoFERGpolAQEZEqCgUREamiUBARkSoKBRERqaJQEBGRKoEOhamFpazfttfvMkRE4kagQ2H8U9MZ+eBUv8sQEYkbgQ4FgIOHK/wuQUQkbiT0MBcNNWVZCe/O31S1/Pu3FzOkR3vGnNzVx6pERPwXyDOF5cW7eHlWUdXyk5+t5kfPzfaxIhGR+BDIUEhuFshmi4jUKZC/HZsnmd8liIjEpUCGQnJS+Ga/PHM901ZtjXE1IiLxI5AdzcnNwp8p/OyV+QCsufeiWJYjIhI3Anmm0LyGMwURkaAL5G/HZPUpiIiEFcxQ0N1HIiJhBfK3Y113Hz0/fR1TlpXEqBoRkfgRyI7muvoUbn9tAaAOZxEJnkCeKahPQUQkvKiFgpk9ZWYlZraw2roOZjbJzJZ739t7683MHjWzFWY238yGRKsu0N1HIiI1ieZvx78Bo49aNxGY7JzrA0z2lgEuBPp4XxOAx6NYV43PKYiIBF3UQsE59wmw7ajV44BnvNfPAJdWW/93F/IVkG5mURuyVGcKIiLhxfq3Y6ZzbhOA972ztz4LWF9tuyJv3THMbIKZzTSzmaWlpQ0q4nj7FN6ct5GPdReSiARIvPzJHO63tAu3oXPuCedcgXOuICMjo0EHO97nFH7y/Byue3pGg44hIpKIYh0KxZWXhbzvlX+GFwHdq22XDWyMVhEaJVVEJLxYh8KbwHjv9XjgjWrrv+vdhXQ6sLPyMlM01DRKqohI0EXt4TUzex44F+hkZkXAb4B7gZfM7AZgHXClt/m7wBhgBbAXuD5adQE0191HIiJhRS0UnHPX1PDWyDDbOuDGaNVyNN19JCISXiB/O9b3ieaKCkdFRdh+bxGRJiWQoVDfM4X8uz7grPumRKkaEZH4EcgB8er7RHPZ/sOU7T8cpWpEROJHIM8UktTRLCISViBDwUyhICISTiBDQUREwgtsKLx+43Ay01r4XYaISFwJbCjkd0+nQ+v6hcLSzWUs2VQWpYpERPwXyLuPKoWemTt+ox/+FNA0nSLSdAX2TEFERI4V6FCo54mCiEiTF+xQCD9lg4hIYAU7FJQJIiJHCHQoVCgVRESOEOhQaGgkPDipkF+9vjCitYiIxINAh0JDPTp5Of/4aq3fZYiIRFywQ0FXj0REjhDoUKjMhKz0Vr7WISISLwIdCumpzQENpS0iUinQofCXbw/lzktOIru9zhRERCDgodA5rSXjz8ht8PMKq7fsYUHRzsgWJSLio0APiFepoU82n3f/x4AGyBORpiPQZwqV9AybiEiIQoGv70JS34KIBJ1CAapSQWcMIhJ0CgWO7VNIa6muFhEJJoUCx54htG3ZvF6f37BjH4s3appOEUl8+pOYr/sUKqfntHo+yzb83o8A3YUkIolPZwrUf65mEZGmSqHAsePiKSNEJKgUCnwdAkdnQWpKUsxrERHxk0IBGJyTDkD71JQj1mugPBEJGoUCcMeYfrz7k7PI6ZB6xPrkeobCQ5MKufRPn0eyNBGRmNLdR0DzpGb075ZWNWdzZcdzfc8UHpm8POK1iYjEks4Uqjm6T6FZfe9NFRFJcAqFaio7nM0LA2WCiASNQuEIR14+qtQ8qX7pUFi8K2IViYjEki+hYGa3mtkiM1toZs+bWUsz62lm08xsuZm9aGYpde8psmq6NTW5Wf3+mS546BNyJ74TmaJERGIo5qFgZlnAT4AC59wAIAm4Gvgf4CHnXB9gO3BDrGurqOGpNd2aKiJB4dflo2SglZklA6nAJmAE8Ir3/jPApbEuqqKGJ5kVCiISFDEPBefcBuB+YB2hMNgJzAJ2OOcOe5sVAVnhPm9mE8xsppnNLC0tjWxtVTUeub6hmXD6/5vcqHpERGLNj8tH7YFxQE+gG9AauDDMpmH/bnfOPeGcK3DOFWRkZES0tgsHdAGgZ6fWEdnf5rL9PPKhnl0QkcThx+WjUcBq51ypc+4Q8BpwBpDuXU4CyAY2xrqwq0/pztLfjSarhmk5U5Lr/8/10IeFjS1LRCRm/AiFdcDpZpZqoQcCRgKLgSnAFd4244E3Yl2YmdGyedIxHc6VSylJDfvnmr1ueyMrExGJDT/6FKYR6lCeDSzwangC+AVwm5mtADoCf411bV8X6X2LUN/CZY990bh6RERixJe7j5xzv3HO5TnnBjjnvuOcO+CcW+WcO9U5d4Jz7krn3AE/aoNqHc7e98ossEY84vyzl+c1piQRkZjQE81h1HT5qDFenlWkGd5EJO4pFMKofF4h0k8nXPWXLxUMIhLXFAph9OwYmlehU5sWQOTCYcaa7ZTtP1z3hiIiPlEohPGTkX149obTOLVnh7Dvt2vVvMH7HnTnBxwqr2jw50VEokmhEEZyUjPO7NOp6lJPYzqYw/ls+ZaI7k9EJFIUCrWo6ep/YzPi+r/NYNf+Q43biYhIFCgUalHTqKmRMPHVBVTUNAKfiIhPFAq1uKqgOwDn9D1yjKVIXEx6Z8Em1m7bG4E9iYhEjkKhFgOz01lz70VkpR85FlLl3/dtWyYf+6F6OO/+j9m5T5eRRCR+KBSOQzQvI2kUVRGJJwqF43DRwK4AnN8/84j1kbiM9NTnq1lZujsCexIRaTyFwnE4qVs71tx7ESd0bgNE/knnkQ9MZduegxHeq4hI/SkU6mFAt3YADM5pH/F93/HaAg2BISK+UyjUw5l9OjHtjpFccNRlpLRGdjgDvL9oM+8t3Nzo/YiINIZCoZ4y01pyeq+OAHxzcNhppBvsR8/NZpX6F0TERwqFBsjt1Jo1915UFQ7JDZyRLZwRD0zVbaoi4huFQiOM6p/Jd4f14NcX94/ofif8faaedhYRXygUGqF5UjPuGjeA7h1CQ2338e5Oaqxpq7fx8GQ9vyAisadQiIAhOencd/lA7ho3IGL7fHTycqYWlkZsfyIix0OhEAFmxlWndKd964bPsxDO+Kems3DDzojuU0SkNgqFCDoxsy2/Gdufy4ZE7q6ki//4Gau37InY/kREaqNQiCAz4/rhPbl5ZJ+I7ve8+z9m0859Ed2niEg4tYaCmX272uvhR73342gVlei6tmtVNb9zpAy75yO27D4Q0X2KiBytrjOF26q9/uNR730vwrU0GSnJzZj536P44bm9I7rfgt9/qDGSRCSq6goFq+F1uGU5yk0jToj4Pof8bhIlu/ZHfL8iIlB3KLgaXodblqOkpiTz4W3nRHy/p949mfWatU1EoqCuUMgzs/lmtqDa68rlE2NQX8I7oXMb3r7pzIjv96z7prB4Y1nE9ysiwVZXKPQDxgIXV3tduRzZsR2asAFZ7fjZNyKfoWMe/ZT3NbKqiERQraHgnFtb/QvYDQwBOnnLcpxuPO8ExpzcJeL7/cGzs7jzrUWUa6wkEYmAum5JfdvMBnivuwILCd119A8zuyUG9TUpj107NCr7ffrzNZx3/8fsPnA4KvsXkeCo6/JRT+fcQu/19cAk59xY4DR0S2qDrLn3oqjsd922vQz4zb/VAS0ijVJXKFQf2H8k8C6Ac24XUBGtopq6JXeNjtq+z7pvCi/NXK/LSSLSIHWFwnozu8nMvkmoL+F9ADNrBUR29LcAaZWSxBcTR0Rt/z9/ZT6jH/6EHXv1oJuI1E9doXADcBJwHfAt59wOb/3pwNNRrKvJ65beig9uPTtq+19espv8uyaxaKNGWRWR42fOJe5lhoKCAjdz5ky/y2iUBUU7Gfu/n0X1GCPzOvPgt/Jp10ondyICZjbLOVcQ9r3aQsHM3qxtx865SxpZW6M0hVAAmL1uO5c99kXUj/Pmj4czMDs96scRkfjWmFAoBdYDzwPTOGq8I+fc1AjWWW9NJRQA5q7fwaV/+jzqxxnUPZ0nv1tARtvIjuIqIomjtlCoq0+hC3AHMAB4BDgf2OKcm9qYQDCzdDN7xcyWmtkSMxtmZh3MbJKZLfe+t2/o/hNRfvd03vlJ5IfDONq89Ts45e4PeWPuBg4e1g1kInKkup5oLnfOve+cG0+oc3kF8LGZ3dTI4z4CvO+cywMGAUuAicBk51wfYLK3HCgndWvHRz+N/AB64dz8wlz6/vd7LN2s8ZNE5Gt1zrxmZi3M7DLgWeBG4FHgtYYe0MzSgLOBvwI45w56dzWNA57xNnsGuLShx0hkvTLaMP2OkTE73uiHP+U7f51GcZmG4xaRuvsUniF06eg94IVqTzc3/IBm+cATwGJCZwmzgJuBDc659GrbbXfOHXMJycwmABMAcnJyhq5d2zSHYNp3sJxRD05lw47YTcP527H9ueqU7qSmJMfsmCISe43paK4AKmeNr76hAc45l9aAYgqAr4DhzrlpZvYIUAbcdDyhUF1T6miuyS//tYDnpq2L6TGf+/5pDD+hU0yPKSKx0+COZudcM+dcW+8rrdpX24YEgqcIKHLOTfOWXyH0tHSxN+he5eB7JQ3cf5Ny9zdP5pGr82N6zGufnEbuxHdYUKQH30SCps4+hUhzzm0mNHxG5QQDIwldSnoTGO+tGw+8Eeva4tW4/Cze/PHwmB937P9+xoWPfMqq0t0xP7aI+MOXJ5q9foUngRRgFaERWJsBLwE5wDrgSufcttr2E4TLR9Vt23OQa574imXFu2J+7MsGZ/Hz0Xl0adcy5scWkchqcJ9CvAtaKFR6Y+4Gbn5hri/H/un5ffnOsB6kp6b4cnwRabzGPLwmcWhcflZUB9OrzQOTCsm/axL/+Gotew9qUh+RpkahkKD6ZrZl6e9Gc8uoPr4c/1evL6T/r//Nv+YUae4GkSZEoZDAWjZP4pZRfXn/lrN8q+HWF+fR+453eXfBJt9qEJHIUSg0AXld0lj2+9HcNe4k32r40XOzyZ34Dh8s2uxbDSLSeAqFJqJFchLfHZbL5xNHkNsx1bc6JvxjFrkT32HykmLfahCRhtPdR03UvPU7GBeDobjr8tR1BYzIy/S7DBGpRncfBdCg7uksuWs0vxzTz9c6vve3meROfIePlurMQSQRKBSasFYpSfzH2b2Y/avzGdXP37/WK8Ph/YXqcxCJZ7p8FCAbd+zjise/YONO/4fJfuTqfMblZ/ldhkgg6YlmqeKcY9WWPYx8wNeZVKvcc9nJXHNqjt9liASKQkGOUV7hmLNuO1f8+Uu/SwHg9gvzmHB2L8ys7o1FpFEUClKj8grHJ4WlXP+3GX6XAsB/ntOLX3wjj2bNFA4i0aJQkDqVVzjeX7iZG/852+9SALiqIJvfXTqAFslJfpci0uQoFOS4VVQ43pq/0bdRWI92Tt8MHvpWPh1aa1RWkUhRKEi9Oed4e/4mbnp+jt+lANA3sw1//vZQemW08bsUkYSnUJAGc84xaXExE/4xy+9SAEhNSeKZ751KQY/26pQWaSCFgkTEFyu28L1nZrD/UIXfpQDwx2sGc+GALiQn6RlMkfpQKEhELSjayc9emcfSzbGfFjScn33jRG44syctm6tTWuR4KBQkKtZs2cNv31rEx8tK/S4FgMuHZPPrsf1p16q536WIxDWFgkTVlt0HeHBSIf+cts7vUgAYlN2OP107hKz0Vup3EAlDoSAxsf9QOU99vpr73l/mdykApCQ145//cRqDuqfTXP0OIlUUChJzr8/ZwC0vxsezDgAPfyufC07KJDUl2e9SRHynUBDffLlyK7e/Np81W/f6XQoAPzinN98/qyed2rTwuxQR3ygUxHeFxbv4v09W8fKsIr9LAeCM3h2557KT6dGxtd+liMScQkHixpbdB3h1VhH3vLfU71IAaJHcjGe/fxr56neQAFEoSNw5XF7Bh0tK+MGz8fGkNMAfrhjIBSd10S2t0uQpFCSuzS/awe/fWcL01dv8LgWA687I5ftn9SS7farfpYhEhUJBEsLGHft4dVYRD0wq9LsUAPK6tOUPVwzi5Ox2fpciElEKBUko+w+V80lhadwMwgfw2LVDOPfEDN3SKk2CQkES1rLNu3jgg2V8sLjY71IAuO38vlxZkE3Xdq38LkWkwRQKkvC27TnIews38ct/LfS7FACG9erI7WPyGJid7ncpIvWmUJAmo7zCsXDDTn7x6vy4GaX1sWuHMCKvs0ZplYShUJAmqWTXfv41e0PcPPNw88g+XFmQrbuWJO4pFKRJO3i4gvlFO7jtpXms2+b/cBpDctK5fUw/Tsnt4HcpImEpFCQwtuw+wIsz1vOHf8fHSK33XnYyYwd1o3UL3bUk8UOhIIFzqLyChRt2MvHVBSwr9r/v4ZpTuzP+jFzyuqT5XYqIQkGCrWz/IV6bVcRv31rsdyk0TzLuv3IQ4/Kz/C5FAiwuQ8HMkoCZwAbn3MVm1hN4AegAzAa+45w7WNs+FApSHxUVjlVb9nDX24v5pND/KUSvPS2HH5zTm+4d1DEtsRWvoXAbUACkeaHwEvCac+4FM/szMM8593ht+1AoSEMdOFzOh4tLuPXFuRwsr/C1lvTU5tw1bgCXDOrmax0SHHEXCmaWDTwD3A3cBowFSoEuzrnDZjYM+K1z7hu17UehIJGwc98h/jh5OU9+ttrvUrhyaDa3nt+Xbul6YlqiJx5D4RXgHqAt8F/AdcBXzrkTvPe7A+855waE+ewEYAJATk7O0LVr18aqbGninHMs3FDG3e8u5qtV/o7Y2rJ5M+6+9GQuG5KFmflaizQ9cRUKZnYxMMY59yMzO5dQKFwPfHlUKLzrnDu5tn3pTEGipaLC8faCTdzz7hI27dzvay2j+nXm9jH96J3Rxtc6pOmoLRT8uHl6OHCJmY0BWgJpwMNAupklO+cOA9nARh9qEwGgWTPjkkHduGRQN3btP8TTn6/hQZ+G9P5wSQkfLikB4I4xeVx3Rk9SkjVLnESHr7ekVp4peB3NLwOvVutonu+ce6y2z+tMQWJtZelunvpsNc9NW+drHb0yWvP7SwdwWs+OJDXT5SWpn7i6fHTEwY8MhV58fUvqHODbzrkDtX1eoSB+mrFmG09/vpp3F2z2tY7Lh2Rz6/l9yEpvpf4HOS5xGwqNpVCQeDF5STH/9+kq3zuof31xf64syKZtS80zLTVTKIjEyJ4Dh5m8tISHJxWyasse3+pIa5nMfVcM5Oy+mi1OjqVQEPHBlt0H+GhpCXe+uYg9B8t9q2Ngdjtuv7Afg3PSNeeDAAoFEd9t3LGPyUtL+NXr/s4cd37/TG4acQJ5XdJ0B1OAKRRE4sj6bXuZtLiYu972d4C+y4dk870zc+mb2ZbmSQqIIFEoiMSpeAmIa07tzrWn9aBvZludQQSAQkEkAWzYsY8PFxfzmzcX+VrH5UOyufb0HPp3TVMfRBOlUBBJMMVl+5mytIQ731rMvkP+dVKP6teZ8WfkMjinPW00e1yToVAQSWBbdx/gsxVbeOCDQl/noM7r0pYfntubYb070rltS9/qkMZTKIg0Ebv2H2LW2u38Zeoqvly11dda7hiTx8h+mRqoLwEpFESaoP2Hyiks3sXz09fz/HR/x2K65tQcLh7YlcE56XpYLgEoFESauIoKx6ay/bw9byP3vLfU11pyO6Zyw1m9OPOETvTs1NrXWiQ8hYJIwOw+cJhPC0t5fOpK5hft9LWWy4dkc9HALgzt0YF2rTQmUzxQKIgE2KHyCgqLd/HqrA089bn/U47+8NzejOqXydAe7f0uJbAUCiIChKYc3XuwnEmLQ6O6LtpY5ms9PTqm8q1TujMirzN5XdJ8rSVIFAoiEpZzjsLi3bwxdwN/nrqSCp9/HfTrmsblQ7IYkdeZXrqrKWoUCiJyXCoqHFMLS3ltzgbemuf/jLh9M9twxdBsRuRl0jujtSYRihCFgog0yNbdB5iyrJQ35m7g0+Vb/C6HrPRWXH1Kd0b0C11u0lSkDaNQEJGIWLt1D58u38Kb8zYyfbW/s8wBpCQ3Y/ywHozql0l+TjotkjVW0/FQKIhIVKwo2cWXq7bxVpyEBMAlg7px4YAunNKzAx1SU2ims4ljKBREJCZWlu5m+uptvLdwM58UlvpdDgADstK4fEg2Z/TuRI+OqRr5FYWCiPhk7dY9zF63nQ8Xl/DOgk1+l1PlujNyOefEDPKz02nfOsXvcmJOoSAicaGkbD/zi3YyZVkJz03zd7ym6k7v1YGLTu7Kab06ktOh6Z9NKBREJC7t2n+IwuLdfLlyCy/MWE/R9n1+lwSAGYwflstZfTpxcna7JjdUuEJBRBLC4fIKNu3cz8y12/hoaWlcPCtRaWiP9lw4oAun9uxAr4w2CT3pkEJBRBJW2f5DFG7exRcrt/La7CLWbPVvoqGjXVWQzdl9MxiYlU5Ox1S/yzluCgURaTLKKxxb9xxgzrodfLq8lGe/ip++iRM6t2HswG6c2rMD/bq2JT01PjuxFQoi0qQdPFzBhh37mLFmG1OWlvDews1+l1Tlgv6ZnJfXmSE57TmxS1u/ywEUCiISQAcPV7CydDcz1mxj0uLiuBimAyA1JYkrh2ZzZp8M8runk9G2RcxrUCiIiBC69LRkUxlfrdrKlGUlfL7C33muK+V3T+eCkzI5o3cnBmW3i/rAfwoFEZEaVFQ4Fm8qY/rqbXyyvJSPl8XHk9hjB3VjZF5nTu/Vkcy0FhENCoWCiEg9VFQ4lm7exZz12/lixda4eBq7e4dWXJqfxdl9M+jariVd0lqSnNSsQftSKIiIRMDy4l0s2ljGtNVbeWPuRvYeLPetlt+O7c91w3s26LO1hULiPn0hIhJjfTLb0iezLZcOzuKeywYCsG7rXpZsLmP22u1MWlLMqtI9Mamlc1p0nrJWKIiINEJOx1RyOqbyjZO6cPuYfkBojKfC4t3MWbedT1dsicqw4tG6a0mhICISYZ3TWtI5rSVn9unETSP7ALBz7yFWbdnN3PU7+HLlVj5YXNy4YygUREQSV7vU5gzOac/gnPZc7/UF7DtYzvrte1lQtJNpq7fyyqwiKo6zmzdag/QpFEREfNIqJYm+mW3pm9mWy4dmc98VgzhUXkHJrgMs3ljGjDXbeHfBprCjx7ZKic7w3jEPBTPrDvwd6AJUAE845x4xsw7Ai0AusAa4yjm3Pdb1iYj4qXlSM7LSW5GV3orz+2dyx5h+OOco23+YpZvKmLVuO+1aNY/a8WN+S6qZdQW6Oudmm1lbYBZwKXAdsM05d6+ZTQTaO+d+Udu+dEuqiEj91XZLasOefGgE59wm59xs7/UuYAmQBYwDnvE2e4ZQUIiISAzFPBSqM7NcYDAwDch0zm2CUHAAnf2rTEQkmHwLBTNrA7wK3OKcK6vH5yaY2Uwzm1laGh9jlIiINBW+hIKZNScUCM85517zVhd7/Q2V/Q4l4T7rnHvCOVfgnCvIyMiITcEiIgER81Cw0FB/fwWWOOcerPbWm8B47/V44I1Y1yYiEnR+PKcwHPgOsMDM5nrr7gDuBV4ysxuAdcCVPtQmIhJoMQ8F59xnQE0Dg4+MZS0iInIkX+8+EhGR+JLQ8ymYWSmwtoEf7wTEx6Stjae2xCe1Jf40lXZA49rSwzkX9k6dhA6FxjCzmTU90Zdo1Jb4pLbEn6bSDoheW3T5SEREqigURESkSpBD4Qm/C4ggtSU+qS3xp6m0A6LUlsD2KYiIyLGCfKYgIiJHUSiIiEiVQIaCmY02s2VmtsKb0CeumdlTZlZiZgurretgZpPMbLn3vb233szsUa9t881siH+VH8nMupvZFDNbYmaLzOxmb30itqWlmU03s3leW+701vc0s2leW140sxRvfQtveYX3fq6f9YdjZklmNsfM3vaWE7ItZrbGzBaY2Vwzm+mtS8SfsXQze8XMlnr/zwyLRTsCFwpmlgT8CbgQ6A9cY2b9/a2qTn8DRh+1biIw2TnXB5jsLUOoXX28rwnA4zGq8XgcBn7qnOsHnA7c6P3bJ2JbDgAjnHODgHxgtJmdDvwP8JDXlu3ADd72NwDbnXMnAA9528WbmwlNelUpkdtynnMuv9p9/In4M/YI8L5zLg8YROi/TfTb4ZwL1BcwDPh3teXbgdv9rus46s4FFlZbXkZoWlOArsAy7/VfgGvCbRdvX4RGwj0/0dsCpAKzgdMIPWGafPTPGvBvYJj3OtnbzvyuvVobsr1fMiOAtwmNT5aobVkDdDpqXUL9jAFpwOqj/11j0Y7AnSkQmvpzfbXlIm9doqlpprqEaN9xzroX123xLrfMJTT3xyRgJbDDOXfY26R6vVVt8d7fCXSMbcW1ehj4OVDhLXckcdvigA/MbJaZTfDWJdrPWC+gFHjau6T3pJm1JgbtCGIohBuhtSndlxv37bPjn3UvrtvinCt3zuUT+iv7VKBfuM2873HbFjO7GChxzs2qvjrMpnHfFs9w59wQQpdUbjSzs2vZNl7bkgwMAR53zg0G9vD1paJwItaOIIZCEdC92nI2sNGnWhqjppnq4rp9Vr9Z9+K6LZWcczuAjwn1k6SbWeWQ9NXrrWqL9347YFtsK63RcOASM1sDvEDoEtLDJGZbcM5t9L6XAP8iFNiJ9jNWBBQ556Z5y68QComotyOIoTAD6OPdWZECXE1o1rdEU9NMdW8C3/XuRjgd2Fl5uuk3s3rPuhfPbckws3TvdStgFKGOwCnAFd5mR7elso1XAB857+Kv35xztzvnsp1zuYT+f/jIOXctCdgWM2ttZm0rXwMXAAtJsJ8x59xmYL2ZneitGgksJhbt8LtDxadOnDFAIaFrwL/0u57jqPd5YBNwiAEs9TMAAACfSURBVNBfBDcQuoY7GVjufe/gbWuE7q5aCSwACvyuv1o7ziR0SjsfmOt9jUnQtgwE5nhtWQj82lvfC5gOrABeBlp461t6yyu893v53YYa2nUu8HaitsWreZ73tajy/+8E/RnLB2Z6P2OvA+1j0Q4NcyEiIlWCePlIRERqoFAQEZEqCgUREamiUBARkSoKBRERqaJQEBGRKgoFERGp8v8B8T+klnTslKUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Affichage graphique\n",
    "plt.plot(Graphique_MSE)\n",
    "plt.ylabel('MSE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "### VERIFICATION DE L'APPRENTISSAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Les probabilités de chaque classe 'Mine' ou 'rocher' issues de l'apprentissage sont stockée dans le modèle.\n",
    "#A l'aide de tf.argmax, on récupére les indexs des probabilités les plus elevées pour chaque observations\n",
    "#Ex: Si pour une observation nous avons [0.56, 0.89] renverra 1 car la valeur la plus élevée se trouve à l'index 1\n",
    "#Ex : Si pour une observation nous avons [0.90, 0.34 ]  renverra 0 car la valeur la plus élevée se trouve à l'index 0\n",
    "classifications = tf.argmax(reseau, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dans le tableau des valeurs réelles :\n",
    "#Les mines sont encodées comme suit [1,0] l'index ayant la plus grande valeur est 0\n",
    "#Les rochers ont pour valeur [0,1] sl'index ayant la plus grande valeur est 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Si la classification est de [0.90, 0.34 ] l'index ayant la plus grande valeur est 0\n",
    "#Si c'est une mine [1,0] l'index ayant la plus grande valeur est 0\n",
    "#Si les deux index sont identiques alors on peut affirmer que c'est une bonne classification\n",
    "formule_calcul_bonnes_classifications = tf.equal(classifications, tf.argmax(tf_valeurs_reelles_Y,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "#La précision se calcul en faisant la moyenne (tf.mean)\n",
    "# des bonnes classifications (aprés les avoir converties en décimale tf.cast, tf.float32)\n",
    "formule_precision = tf.reduce_mean(tf.cast(formule_calcul_bonnes_classifications, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PRECISION SUR LES DONNEES DE TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Classe attendue:  1  Classification:  1\n",
      "1 Classe attendue:  0  Classification:  0\n",
      "2 Classe attendue:  1  Classification:  1\n",
      "3 Classe attendue:  1  Classification:  1\n",
      "4 Classe attendue:  0  Classification:  0\n",
      "5 Classe attendue:  1  Classification:  1\n",
      "6 Classe attendue:  0  Classification:  0\n",
      "7 Classe attendue:  1  Classification:  1\n",
      "8 Classe attendue:  1  Classification:  0\n",
      "9 Classe attendue:  0  Classification:  0\n",
      "10 Classe attendue:  0  Classification:  0\n",
      "11 Classe attendue:  0  Classification:  0\n",
      "12 Classe attendue:  0  Classification:  0\n",
      "13 Classe attendue:  1  Classification:  0\n",
      "14 Classe attendue:  0  Classification:  0\n",
      "15 Classe attendue:  1  Classification:  1\n",
      "16 Classe attendue:  1  Classification:  0\n",
      "17 Classe attendue:  0  Classification:  0\n",
      "18 Classe attendue:  0  Classification:  0\n",
      "19 Classe attendue:  0  Classification:  0\n",
      "20 Classe attendue:  1  Classification:  0\n",
      "21 Classe attendue:  0  Classification:  0\n",
      "22 Classe attendue:  1  Classification:  1\n",
      "23 Classe attendue:  1  Classification:  0\n",
      "24 Classe attendue:  0  Classification:  0\n",
      "25 Classe attendue:  0  Classification:  0\n",
      "26 Classe attendue:  0  Classification:  0\n",
      "27 Classe attendue:  1  Classification:  1\n",
      "28 Classe attendue:  0  Classification:  0\n",
      "29 Classe attendue:  1  Classification:  1\n",
      "30 Classe attendue:  0  Classification:  0\n",
      "31 Classe attendue:  0  Classification:  0\n",
      "32 Classe attendue:  1  Classification:  1\n",
      "33 Classe attendue:  0  Classification:  0\n",
      "34 Classe attendue:  0  Classification:  0\n",
      "35 Classe attendue:  1  Classification:  0\n",
      "36 Classe attendue:  1  Classification:  0\n",
      "37 Classe attendue:  0  Classification:  0\n",
      "38 Classe attendue:  0  Classification:  0\n",
      "39 Classe attendue:  1  Classification:  1\n",
      "40 Classe attendue:  1  Classification:  0\n",
      "41 Classe attendue:  1  Classification:  1\n"
     ]
    }
   ],
   "source": [
    "nb_classifications = 0;\n",
    "nb_bonnes_classifications = 0\n",
    "\n",
    "#On parcours l'ensemble des données de test (text_x)\n",
    "for i in range(0,test_x.shape[0]):\n",
    "\n",
    "    #On récupere les informations\n",
    "    donneesSonar = test_x[i].reshape(1,60)\n",
    "    classificationAttendue = test_y[i].reshape(1,2)\n",
    "\n",
    "    # On réalise la classification\n",
    "    prediction_run = session.run(classifications, feed_dict={tf_neurones_entrees_X:donneesSonar})\n",
    "\n",
    "    #On calcule la précision de la classification à l'aide de la formule établie auparavant\n",
    "    accuracy_run = session.run(formule_precision, feed_dict={tf_neurones_entrees_X:donneesSonar, tf_valeurs_reelles_Y:classificationAttendue})\n",
    "\n",
    "\n",
    "    #On affiche pour observation la classe originale et la classification réalisée\n",
    "    print(i,\"Classe attendue: \", int(session.run(tf_valeurs_reelles_Y[i][1],feed_dict={tf_valeurs_reelles_Y:test_y})), \" Classification: \", prediction_run[0] )\n",
    "\n",
    "    nb_classifications = nb_classifications+1\n",
    "    if(accuracy_run*100 ==100):\n",
    "        nb_bonnes_classifications = nb_bonnes_classifications+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------\n",
      "Précision sur les donnees de tests = 80.95238095238095%\n"
     ]
    }
   ],
   "source": [
    "print(\"-------------\")\n",
    "print(\"Précision sur les donnees de tests = \"+str((nb_bonnes_classifications/nb_classifications)*100)+\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PRECISION SUR LES DONNEES D'APPRENTISSAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classifications = 0;\n",
    "nb_bonnes_classifications = 0\n",
    "for i in range(0,train_x.shape[0]):\n",
    "\n",
    "    # On récupere les informations\n",
    "    donneesSonar = train_x[i].reshape(1, 60)\n",
    "    classificationAttendue = train_y[i].reshape(1, 2)\n",
    "\n",
    "    # On réalise la classification\n",
    "    prediction_run = session.run(classifications, feed_dict={tf_neurones_entrees_X: donneesSonar})\n",
    "\n",
    "    # On calcule la précision de la classification à l'aide de la formule établie auparavant\n",
    "    accuracy_run = session.run(formule_precision, feed_dict={tf_neurones_entrees_X: donneesSonar, tf_valeurs_reelles_Y: classificationAttendue})\n",
    "\n",
    "    nb_classifications = nb_classifications + 1\n",
    "    if (accuracy_run * 100 == 100):\n",
    "        nb_bonnes_classifications = nb_bonnes_classifications + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Précision sur les donnees d'apprentissage = 88.55421686746988%\n"
     ]
    }
   ],
   "source": [
    "print(\"Précision sur les donnees d'apprentissage = \" + str((nb_bonnes_classifications / nb_classifications) * 100) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PRECISION SUR L'ENSEMBLE DES DONNEES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classifications = 0;\n",
    "nb_bonnes_classifications = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,207):\n",
    "\n",
    "    prediction_run = session.run(classifications, feed_dict={tf_neurones_entrees_X:X[i].reshape(1,60)})\n",
    "    accuracy_run = session.run(formule_precision, feed_dict={tf_neurones_entrees_X:X[i].reshape(1,60), tf_valeurs_reelles_Y:Y[i].reshape(1,2)})\n",
    "\n",
    "    nb_classifications = nb_classifications + 1\n",
    "    if (accuracy_run * 100 == 100):\n",
    "        nb_bonnes_classifications = nb_bonnes_classifications + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Précision sur l'ensemble des données = 86.95652173913044%\n"
     ]
    }
   ],
   "source": [
    "print(\"Précision sur l'ensemble des données = \" + str((nb_bonnes_classifications / nb_classifications) * 100) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
